{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61b384b4-67ee-4a40-ac56-776287a93a38",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Times New Roman', serif; font-size: 14px;\">\n",
    "\n",
    "# Script Overview\n",
    "\n",
    "`In this script: `<br>\n",
    "`1. We create a database using SQLite.`<br>\n",
    "`2. We add all CSV files into the database \"inventory.db\" as tables. ` \n",
    "\n",
    "# Need of the Script\n",
    "\n",
    "- Data is continuously received from the server in the form of CSV files.  \n",
    "- Managing these CSV files manually is time-consuming and error-prone.  \n",
    "- By using a script:\n",
    "  - We can **automate the process** of storing CSV files into a database.  \n",
    "  - All data is stored in a **single database (`inventory.db`)**, making it easier to query and analyze.  \n",
    "  - Ensures **data consistency and integrity**.  \n",
    "  - Provides a **scalable solution** for handling continuous incoming data.  \n",
    "\n",
    "## Example of Automation Scipt\n",
    "`For example, if your data is coming every 15 minutes in the form of CSV, you can write a script that runs automatically every 15   minutes and Whenever the script runs, it will read the latest CSV file and **store the data into the database**.`<br>`This way, scripting helps to keep the database **up-to-date without manual intervention**.`\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdf16336-a7e6-4bd6-a551-04b7f796f6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa752bb0-8e97-4101-8ec4-2cdfc7f727df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a connection engine to the SQLite database named 'inventory.db'\n",
    "engine = create_engine('sqlite:///inventory.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bd2fdd-5173-40c6-a856-983d4beef7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir('data'):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29b692f5-e069-447c-91d2-93f1bd50792c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin_inventory.csv: (206529, 9)\n",
      "end_inventory.csv: (224489, 9)\n",
      "purchases.csv: (2372474, 16)\n",
      "purchase_prices.csv: (12261, 9)\n",
      "sales.csv: (12825363, 14)\n",
      "vendor_invoice.csv: (5543, 10)\n"
     ]
    }
   ],
   "source": [
    "# Iterate through files in 'data' directory\n",
    "for file in os.listdir('data'):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join('data', file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"{file}: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32ab8a8e-6c57-40ef-8e08-b8df475591a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing begin_inventory.csv (16.64 MB)...\n",
      "Processing end_inventory.csv (18.10 MB)...\n",
      "Processing purchases.csv (344.83 MB)...\n",
      "Processing purchase_prices.csv (1.00 MB)...\n",
      "Processing sales.csv (1522.76 MB)...\n",
      "Processing vendor_invoice.csv (0.49 MB)...\n"
     ]
    }
   ],
   "source": [
    "# List all CSV files in the 'data' folder and print their size in megabytes\n",
    "for file in os.listdir('data'):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join('data', file)\n",
    "        size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "        print(f\"Processing {file} ({size_mb:.2f} MB)...\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e1b5f04-90ba-4b4e-a771-58c468fc6693",
   "metadata": {},
   "source": [
    "Read CSV in chunks -> recommended for larger csv(more than 1Gb) file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe836564-a7ae-445f-ac48-69f0fee0a9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_csv_in_chunks(file_path, table_name, engine, chunk_size=100000):\n",
    "    \"\"\"\n",
    "    Ingests a large CSV file into a database in chunks.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the CSV file.\n",
    "        table_name (str): Name of the target table.\n",
    "        engine (SQLAlchemy Engine): SQLAlchemy database engine.\n",
    "        chunk_size (int): Number of rows per chunk.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    first_chunk = True\n",
    "    for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "        if_exists_mode = 'replace' if first_chunk else 'append'\n",
    "        chunk.to_sql(table_name, con=engine, if_exists=if_exists_mode, index=False)\n",
    "        first_chunk = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e31f40c-dffb-4c8c-bdb4-e7c9634a0065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunked ingesting: begin_inventory.csv\n",
      "Chunked ingesting: end_inventory.csv\n",
      "Chunked ingesting: purchases.csv\n",
      "Chunked ingesting: purchase_prices.csv\n",
      "Chunked ingesting: sales.csv\n",
      "Chunked ingesting: vendor_invoice.csv\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir('data'):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join('data', file)\n",
    "        table_name = os.path.splitext(file)[0]\n",
    "        print(f\"Chunked ingesting: {file}\")\n",
    "        ingest_csv_in_chunks(file_path, table_name, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f0dcab-19f8-4bad-90f0-48639b16edbf",
   "metadata": {},
   "source": [
    "<!-- table_name = os.path.splitext(file)[0]\n",
    "This line extracts the filename without its extension (like .csv) to use it as the table name for database insertion\n",
    "\n",
    "Breakdown:\n",
    "os.path.splitext(file)\n",
    "    This function splits the filename into two parts:\n",
    "    [0] → the name part (before the extension)\n",
    "    [1] → the extension (like .csv, .txt, etc.) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6092af3-4a93-43f9-a4ab-0103112067f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Ensure the logs directory exists\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename=\"logs/ingestion_db.log\",\n",
    "    level=logging.DEBUG,  # DEBUG captures everything\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    filemode=\"a\"  # Append mode; use \"w\" to overwrite each time\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa9e17-1604-4cf7-8115-613a82c84be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def load_raw_data():\n",
    "    '''Load CSVs from data/ and ingest into DB'''\n",
    "    data_dir = 'data'\n",
    "    \n",
    "    if not os.path.exists(data_dir):\n",
    "        logging.error(f\"Data directory '{data_dir}' does not exist.\")\n",
    "        return\n",
    "    \n",
    "    logging.info(\"Starting to load raw CSV files from 'data' directory.\")\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    for file in os.listdir(data_dir):\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(data_dir, file)\n",
    "            table_name = os.path.splitext(file)[0]\n",
    "            \n",
    "            logging.info(f\"Starting chunked ingestion for file: {file}\")\n",
    "            \n",
    "            try:\n",
    "                ingest_csv_in_chunks(file_path, table_name, engine)\n",
    "                logging.info(f\"Successfully ingested file: {file} into table: {table_name}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to ingest file: {file} — Error: {e}\")\n",
    "    \n",
    "    end = time.time()\n",
    "    total_time = (end - start) / 60  # in minutes\n",
    "    logging.info(\"Finished loading all raw CSV files.\")\n",
    "    logging.info(f\"Total Time Taken: {total_time:.2f} minutes\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    load_raw_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf33838c-c793-4cb9-894c-4a46f9e3246f",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "## <u>Connected with Me</u>\n",
    "\n",
    "<div style=\"font-family: 'Times New Roman', Times, serif; font-size: 16px; line-height: 2; text-align: center;\">\n",
    "    <a href=\"mailto:thisside.faisalkhan@example.com\">Email Me</a><br>\n",
    "    <a href=\"https://www.linkedin.com/in/faisal-khan-332b882bb/\">LinkedIn</a><br>\n",
    "    <a href=\"https://github.com/Faisal-khann\">GitHub</a>\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"font-family: 'Times New Roman', Times, serif; font-size: 16px; padding: 12px;\">\n",
    "    Made with <span style=\"color: #e25555;\">❤️</span> by <strong>Faisal Khan</strong><br>\n",
    "    <span style=\"color: gray; font-size: 13px;\">Powered by Jupyter Notebook</span>\n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a426b786-f085-4849-86dc-8af1a0913638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook successfully converted to HTML: ingesting_Scripting.html\n"
     ]
    }
   ],
   "source": [
    "import nbformat\n",
    "from nbconvert import HTMLExporter\n",
    "\n",
    "# Load the Jupyter Notebook with UTF-8 encoding\n",
    "with open(\"ingesting-logs workbook.ipynb\", \"r\", encoding=\"utf-8\") as f:\n",
    "    nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "# Create an HTML exporter\n",
    "html_exporter = HTMLExporter()\n",
    "html_exporter.template_name = \"classic\"  # or \"lab\", \"reveal\", etc.\n",
    "\n",
    "# Convert the notebook to HTML\n",
    "body, resources = html_exporter.from_notebook_node(nb)\n",
    "\n",
    "# Save the HTML output\n",
    "output_file = \"ingesting_Scripting.html\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(body)\n",
    "\n",
    "print(f\"Notebook successfully converted to HTML: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7d75d1-bc1e-4ed2-974d-a6a14c86a71e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
